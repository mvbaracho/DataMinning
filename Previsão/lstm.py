# -*- coding: utf-8 -*-
"""LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Sa99V_JIrZYPhoeCbXg5I0EhxxXbB8Af
"""

#BIBLIOTECAS
!pip install pycaret
!pip install scikit-learn

import datetime as dt
import pandas as pd
import tensorflow as tf
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
from sklearn import preprocessing
from matplotlib.pylab import rcParams
import matplotlib.pyplot as plt
import numpy as np
import math
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from keras.layers import Dropout
from sklearn.preprocessing import MinMaxScaler

# IMPORTAÇÃO DB
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

downloaded = drive.CreateFile({'id':"138bRT5WPXfCdZj2fS_sMars4NlaQr75y"})
downloaded.GetContentFile('Sales2.csv')

# CARREGANDO DB
df = pd.read_csv('Sales2.csv', sep=';', na_values='?')
df.head()

# Trata a coluna Timestamp
df['Timestamp']= pd.to_datetime(df['Timestamp'],format='%Y-%m-%d')

# Obtém a coluna Price(Somatório das vendas do dia)
df_class2 = df[['Timestamp', 'Price']].groupby(pd.Grouper(key='Timestamp', freq='1D')).sum()['Price']

# A partir daqui, um novo dataframe será gerado(df2) para trabalharmos
df2 = pd.DataFrame(df_class2)

df2['Price']

# Normalização dos dados
normalized_df=(df2-df2.min())/(df2.max()-df2.min())
normalized_df

train_size = int(len(normalized_df) * 0.75)
test_size = len(normalized_df) - train_size
training_set = normalized_df.iloc[:train_size, :].values
test_set = normalized_df.iloc[train_size:, :].values

# Feature Scaling - verificar se precisa
sc = MinMaxScaler(feature_range = (0, 1))
training_set_scaled = sc.fit_transform(training_set)
# Creating a data structure with 60 time-steps and 1 output
X_train = []
y_train = []
das = 7
for i in range(das, train_size):
    X_train.append(training_set_scaled[i-das:i, 0])
    y_train.append(training_set_scaled[i, 0])
X_train, y_train = np.array(X_train), np.array(y_train)
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

model = Sequential()
#Adding the first LSTM layer and some Dropout regularisation
model.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))
model.add(Dropout(0.2))
# Adding a second LSTM layer and some Dropout regularisation
model.add(LSTM(units = 50, return_sequences = True))
model.add(Dropout(0.2))
# Adding a third LSTM layer and some Dropout regularisation
model.add(LSTM(units = 50, return_sequences = True))
model.add(Dropout(0.2))
# Adding a fourth LSTM layer and some Dropout regularisation
model.add(LSTM(units = 50))
model.add(Dropout(0.2))
# Adding the output layer
model.add(Dense(units = 1))

# Compiling the RNN
model.compile(optimizer = 'adam', loss = 'mean_squared_error')

# Fitting the RNN to the Training set
model.fit(X_train, y_train, epochs = 150, batch_size = 32)

dataset_train = normalized_df.iloc[:train_size, :]
dataset_test = normalized_df.iloc[train_size:, :]
dataset_total = pd.concat((dataset_train, dataset_test), axis = 0)
inputs = dataset_total[len(dataset_total) - len(dataset_test) - das:].values
inputs = inputs.reshape(-1,1)
inputs = sc.transform(inputs)
X_test = []
y_test = []
for i in range(das, (test_size+das)):
    X_test.append(inputs[i-das:i, 0])
    y_test.append(inputs[i, 0])
X_test = np.array(X_test)
y_test = np.array(y_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))
print(X_test.shape)

predicted_stock_price = model.predict(X_test)
predicted_stock_price = sc.inverse_transform(predicted_stock_price)

normalized_df['Timestamp'] = normalized_df.index
normalized_df = normalized_df.reset_index(drop=True)

# Visualising the results
plt.plot(normalized_df.loc[train_size:, 'Timestamp'],dataset_test.values, color = 'red', label = 'Real value')
plt.plot(normalized_df.loc[train_size:, 'Timestamp'],predicted_stock_price, color = 'blue', label = 'Predicted value')
plt.title('Previsão diaria de vendas')
plt.xlabel('Time')
plt.ylabel('valor')
plt.legend()
plt.show()

dataset_test['predicted'] = predicted_stock_price
dataset_test

scaler = MinMaxScaler(feature_range = (0, 1))
obj1 = scaler.fit([y_test])
testY = obj1.inverse_transform([y_test])
testScore = math.sqrt(mean_squared_error(testY[0], predicted_stock_price[:,0]))
print('Test Score: %.2f RMSE' % (testScore))

df2['predicted'] = df2['Price']
desnormalized = (dataset_test+df2.min())*(df2.max()+df2.min())
desnormalized

