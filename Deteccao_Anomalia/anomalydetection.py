# -*- coding: utf-8 -*-
"""AnomalyDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A7O4IX7ivbuytc5gjN4tOyJYTH0SM-0A

# Setup
"""

# Commented out IPython magic to ensure Python compatibility.
#BIBLIOTECAS

import numpy as np
import datetime as dt
import matplotlib.pyplot as plt
from matplotlib.ticker import PercentFormatter
import pandas as pd
import seaborn as sns
import statistics
import datetime as dt
import calendar
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
from sklearn import preprocessing

# %matplotlib inline
# IMPORTAÇÃO DB


auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

downloaded = drive.CreateFile({'id':"138bRT5WPXfCdZj2fS_sMars4NlaQr75y"})
downloaded.GetContentFile('Sales2.csv')

"""# Carregamento da Base de dados"""

# CARREGANDO DB
df = pd.read_csv('Sales2.csv', sep=';', na_values='?')
df.head()

"""## Pré-processamento"""

# Trata a coluna Timestamp e insere a coluna Weekday necessária para realizar os próximos cálculos
df['Timestamp']= pd.to_datetime(df['Timestamp'],format='%Y-%m-%d')
df['Weekday'] = df['Timestamp'].dt.day_name()
df

#Calcula a quantidade de cada dia da semana na base 
start = df['Timestamp'].min().strftime('%Y-%m-%d')
end = df['Timestamp'].max().strftime('%Y-%m-%d')
weekday = ['Sat', 'Fri', 'Tue', 'Mon', 'Thu', 'Wed', 'Sun']

qnt_weekday = []
for elem in weekday:
  qtd = np.busday_count(start, end, weekmask=elem)
  qnt_weekday.append((elem,qtd))

qnt_weekday

#Calcula a média total de vendas de acordo com o dia da semana, retornando uma lista de tuplas com o dia da semana e sua média de vendas
weekday_rec = df['Weekday'].value_counts()
weekday_mean = []
weekday_values = []
for elem in weekday_rec:
  weekday_values.append(elem)

i = 0
for elem, value in qnt_weekday:
    weekday_mean.append((elem,round(weekday_values[i]/value)))
    i += 1
weekday_mean

# Pré-processamento: obtém a coluna Price(Somatório das vendas do dia) e insere a coluna Weekday
df_class2 = df[['Timestamp', 'Price']].groupby(pd.Grouper(key='Timestamp', freq='1D')).sum()['Price']
# A partir daqui, um novo dataframe será gerado(df2) para trabalharmos
df2 = pd.DataFrame(df_class2)
# Tratamento para que a coluna Timestamp seja criada(o index está como Timestamp, por isso a necessidade dessa atribuição)
df2['Timestamp'] = df2.index
# Necessário dropar o index Timestamp para que o index seja resetado para inteiros
df2 = df2.reset_index(drop=True)
# Coluna Weekday inserida novamente de acordo com os novos Timestamps
df2['Weekday'] = df2['Timestamp'].dt.day_name()
df2 = df2.rename(columns={'Price':'Amount'})
df2

# Pré-processamento -> LabelEncoder para transformar strings para inteiros
le = preprocessing.LabelEncoder()
df2['Weekday'] = le.fit_transform(df2['Weekday'])
df2

#Dicionário criado para associar o dia ao seu valor do DataFrame
dc = {'Sun': 0, 'Mon': 1, 'Tue': 2, 'Wed': 3,'Thu': 4,
 'Fri': 5,
 'Sat': 6}
x = []
# Itera sobre o a lista weekday_mean para associar o valor do dia da semana(0 a 6) com a média de vendas desse dia. ex: 0: 643(Domingo);  6: 2007(Sábbado)
for elem in weekday_mean:
   x.append((dc[elem[0]],elem[1]))
  
#transforma x num dicionário
x = dict(x)

# Obtém 2 arrays:   array z -> obtém todos os Prices(Amount)  array y -> obtém todos os dias (0 a 6)
z, y = df2.values[:, 0], df2.values[:, -1]
analysis = []
for i in range(len(z)):
    if z[i] >= x[y[i]]:
      analysis.append('Good') 
    else:
      analysis.append('Bad')
#atribui a lista gerada para uma nova coluna(Analysis)
df2['Analysis'] = analysis
df2

df2['Analysis'] = le.fit_transform(df2['Analysis'])
df2

plt.scatter(df2['Weekday'],df2['Amount'])
plt.show()

plt.hist(df2['Amount'])

"""##**Isolation Forest**"""

from pandas import read_csv
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import IsolationForest
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import MinMaxScaler

# Normalização dos dados
#x = (x-x.min())/(x.max()-x.min())
scaler = MinMaxScaler()
df3 = df2.drop(columns=['Timestamp'])
data = scaler.fit_transform(df3)

#Isolation Forest with Analysis column
iso = IsolationForest(contamination=0.05)
y_pred = iso.fit_predict(data)
y_pred

df2['IsOutlier'] = y_pred
df2

# Returns the number of outliers
def qtyOutliers(y_pred):
  c= 0
  for item in y_pred:
    if item == -1:
      c+=1
  return c
qtyOutliers(y_pred)

"""## **Isolation Forest - Teste 2**"""

from pandas import read_csv
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import IsolationForest
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import MinMaxScaler

# Normalização dos dados
#x = (x-x.min())/(x.max()-x.min())
scaler = MinMaxScaler()
df3 = df2.drop(columns=['Timestamp','Analysis'])
data2 = scaler.fit_transform(df3)

#Isolation Forest without Analysis column
iso = IsolationForest(contamination=0.05)
y_pred2 = iso.fit_predict(data2)
y_pred2

df3['IsOutlier'] = y_pred2
df3

qtyOutliers(y_pred)

sns.boxplot(x='Weekday', y='Amount', data=df2)

"""##**Local Outlier Factor**"""

# evaluate model performance with outliers removed using local outlier factor
from pandas import read_csv
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import LocalOutlierFactor
from sklearn.metrics import mean_absolute_error

lof = LocalOutlierFactor(contamination=0.05)
ypred3 = lof.fit_predict(data)
# select all rows that are not outliers

ypred3

df2['IsOutlier'] = ypred3
df2

qtyOutliers(ypred3)